# -*- coding: utf-8 -*-
"""RNN_v4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1AsKxvf1hZdC8I68D521qZxHbKzF7M6PZ

#Single dimensional with treatment
"""

from google.colab import drive
drive.mount('/content/drive')

#data_path = '/content/drive/My Drive/DL4H/DL4H_Project/Bi_dimensional/data'
data_path = '/content/drive/My Drive/DL4H/Project/Paper46/Data'

"""Import packages"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MultiLabelBinarizer
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch.nn.utils.rnn import pad_sequence
import matplotlib.pyplot as plt

"""Read data"""

data= pd.read_pickle(data_path + '/data-1.pkl')

data.rename(columns={'itemid': 'symptom', 'formulary_drug_cd': 'treatment', 'icd9_code': 'diagnosis'}, inplace=True)

data.head()

print(data.dtypes)
print(data.iloc[0]['symptom'][0])

"""create vocabularies"""

#vocabulary of symptom
symp =  data['symptom'].to_numpy()
symptom = set()
for s in symp:
  symptom.update(s)
vocab_symptom = list(symptom)
print(vocab_symptom)
print(len(vocab_symptom))

#vocabulary of treatment
treat =  data['treatment'].to_numpy()
treatment = set()
for s in treat:
  treatment.update(s)
vocab_treatment = list(treatment)
print(vocab_treatment)
print(len(vocab_treatment))

#vocabulary of diagnosis
diag = data['diagnosis'].to_numpy()
diagnosis = set()
for s in diag:
  diagnosis.update(s)
vocab_diagnosis = list(diagnosis)
print(vocab_diagnosis)
print(len(vocab_diagnosis))

"""# Multi-hot Encoding"""

symptom_encoder = MultiLabelBinarizer()
treatment_encoder = MultiLabelBinarizer()
diagnosis_encoder = MultiLabelBinarizer()

mh_symptom = symptom_encoder.fit_transform(data['symptom'])
print(type(mh_symptom))
print(mh_symptom.shape)
print(mh_symptom)

data['mh_symptom'] = symptom_encoder.fit_transform(data['symptom']).tolist()
data['mh_treatment'] = treatment_encoder.fit_transform(data['treatment']).tolist()
data['mh_diagnosis'] = diagnosis_encoder.fit_transform(data['diagnosis']).tolist()

print(data.columns)
print(data.head(5))

data['idx_symptopm'] = data['mh_symptom'].apply(lambda x: np.where(np.array(x) == 1)[0])#.tolist()
data['idx_treatment'] = data['mh_treatment'].apply(lambda x: np.where(np.array(x) == 1)[0])#.tolist()
data['idx_diagnosis'] = data['mh_diagnosis'].apply(lambda x: np.where(np.array(x) == 1)[0])#.tolist()

print(data)

"""#Group by"""

data_gb = data.groupby('subject_id')

'''for name, group in data_gb:
  print(group['symptom'], name)'''
  
subjects= data['subject_id'].unique()

"""#single dim"""

class Treatment2Vec(nn.Module):
  def __init__(self, treatment_size, emb_dim=16):
    super(Treatment2Vec, self).__init__()

    self.rnn = nn.RNN(input_size=treatment_size, hidden_size=emb_dim, nonlinearity= 'tanh', bias=True, batch_first=True)

  def forward(self, treatment):

    o, h = self.rnn(treatment)

    return o, h

"""#Diagnosis_Pred"""

class Diagnosis_Pred(nn.Module):
  def __init__(self, emb_dim, diagnosis_size):
    super(Diagnosis_Pred, self).__init__()

    self.fc1 = nn.Linear(in_features = emb_dim, out_features = diagnosis_size)

  def forward(self, o_hidden):
      return F.softmax(self.fc1(o_hidden))

trt2vec = Treatment2Vec(len(vocab_treatment))
diag_pred = Diagnosis_Pred(emb_dim=16, diagnosis_size=len(vocab_diagnosis))

params = list(trt2vec.parameters()) + list(diag_pred.parameters())

optimizer = torch.optim.Adam(params, lr=1e-3)
criterion= nn.BCELoss()

"""Dataset"""

class Mimic3(Dataset):
    # load the dataset
    def __init__(self,data_gb, subjects):
        self.subjects= subjects
        self.data_gb = data_gb

    # number of rows in the dataset
    def __len__(self):
        return self.subjects.shape[0]

    # get a row at an index
    def __getitem__(self, idx):
        subject_id=subjects[idx]
        group = self.data_gb.get_group(subject_id)
        #s1 = np.array(group['symptom'].values.tolist())
        #print(s1.shape)
        s = torch.from_numpy(np.array(group['mh_treatment'].values.tolist(), dtype = 'float32') )
        d = torch.from_numpy(np.array(group['mh_diagnosis'].values.tolist(),dtype = 'float32'))

        return [s, d]

def collate_fn(batch):
  #print(type(batch[0][0]))
  symptoms = []
  treatments = []
  for patient in batch:
    symptoms.append(patient[0])
    treatments.append(patient[1])

  symptoms = pad_sequence(symptoms, batch_first=True)
  treatments = pad_sequence(treatments, batch_first=True)
  print(symptoms.shape)
  print(treatments.shape)
  return symptoms, treatments

full_set = Mimic3(data_gb, subjects)
total_size = len(full_set)
val_size = int(0.1 * total_size)
test_size = val_size
train_size = total_size - val_size - test_size
train_set, val_set, test_set = torch.utils.data.random_split(full_set, [train_size, val_size, test_size])

train_loader= DataLoader(train_set, batch_size= 24, shuffle = True, collate_fn=collate_fn)
val_loader= DataLoader(val_set, batch_size= 24, shuffle = True, collate_fn=collate_fn)
test_loader= DataLoader(test_set, batch_size= 24, shuffle = False, collate_fn=collate_fn)

def collate_fn(batch):
  treatments = []
  diagnoses = []

  for patient in batch:
    treatments.append(patient[0])
    diagnoses.append(patient[1])

  treatments = pad_sequence(treatments, batch_first=True)
  diagnoses = pad_sequence(diagnoses, batch_first=True)
  
  print(treatments.shape)
  print(diagnoses.shape)
  
  return treatments, diagnoses

trt2vec_params = sum(p.numel() for p in trt2vec.parameters())
trt2vec_train_params = sum(p.numel() for p in trt2vec.parameters() if p.requires_grad)
diag_pred_params = sum(p.numel() for p in diag_pred.parameters())
diag_pred_train_params = sum(p.numel() for p in diag_pred.parameters() if p.requires_grad)
print(trt2vec_params, trt2vec_train_params)
print(diag_pred_params, diag_pred_train_params)

def my_plot(epochs, loss):
    plt.plot(epochs, loss)
    plt.xlabel('Epoch No')
    plt.ylabel('BCE Loss')
    plt.show()

num_epochs= 250
loss_vals=  []
for epoch in range(num_epochs):
    # enumerate mini batches
    epoch_loss= []
    for i, (treatment, diagnosis) in enumerate(train_loader):
        print(treatment)
        # clear the gradients
        optimizer.zero_grad()
        # compute the model output
        #rep = pat2vec(symptom, treatment)
        rep, _ = trt2vec(treatment)
        yhat = diag_pred(rep)
        # calculate loss
        loss = criterion(yhat, diagnosis)
        # credit assignment
        loss.backward(retain_graph=True)
        epoch_loss.append(loss.item())
        # update model weights
        optimizer.step()
    loss_vals.append(sum(epoch_loss)/len(epoch_loss))
# plotting
my_plot(np.linspace(1, num_epochs, num_epochs).astype(int), loss_vals)
