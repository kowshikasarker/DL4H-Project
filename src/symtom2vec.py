# -*- coding: utf-8 -*-
"""RNN_v3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1niBQEx30cq8F6LurDvaNtzGoumyISffD
"""

from google.colab import drive
drive.mount('/content/drive')

"""#Single dimensional with symptom"""

#data_path = '/content/drive/My Drive/DL4H/DL4H_Project/Bi_dimensional/data'
data_path = '/content/drive/My Drive/DL4H/Project/Paper46/Data'

"""Import packages"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import MultiLabelBinarizer
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
from torch.utils.data import DataLoader
from torch.nn.utils.rnn import pad_sequence

if torch.cuda.is_available():
    device = torch.device("cuda:0")
    print("Running on the GPU")
else:
    device = torch.device("cpu")
    print("Running on the CPU")

"""Read data"""

data= pd.read_pickle(data_path + '/data-1.pkl')

print(data.shape)

data.rename(columns={'itemid': 'symptom', 'formulary_drug_cd': 'treatment', 'icd9_code': 'diagnosis'}, inplace=True)

data.head()

print(data.dtypes)
print(data.iloc[0]['symptom'][0])

"""create vocabularies"""

#vocabulary of symptom
symp =  data['symptom'].to_numpy()
symptom = set()
for s in symp:
  symptom.update(s)
vocab_symptom = list(symptom)
print(vocab_symptom)
print(len(vocab_symptom))

#vocabulary of treatment
treat =  data['treatment'].to_numpy()
treatment = set()
for s in treat:
  treatment.update(s)
vocab_treatment = list(treatment)
print(vocab_treatment)
print(len(vocab_treatment))

#vocabulary of diagnosis
diag = data['diagnosis'].to_numpy()
diagnosis = set()
for s in diag:
  diagnosis.update(s)
vocab_diagnosis = list(diagnosis)
print(vocab_diagnosis)
print(len(vocab_diagnosis))

"""# Multi-hot Encoding"""

symptom_encoder = MultiLabelBinarizer()
treatment_encoder = MultiLabelBinarizer()
diagnosis_encoder = MultiLabelBinarizer()

mh_symptom = symptom_encoder.fit_transform(data['symptom'])
print(type(mh_symptom))
print(mh_symptom.shape)
print(mh_symptom)

data['mh_symptom'] = symptom_encoder.fit_transform(data['symptom']).tolist()
data['mh_treatment'] = treatment_encoder.fit_transform(data['treatment']).tolist()
data['mh_diagnosis'] = diagnosis_encoder.fit_transform(data['diagnosis']).tolist()

print(data.columns)
print(data.head(5))

data['idx_symptopm'] = data['mh_symptom'].apply(lambda x: np.where(np.array(x) == 1)[0])#.tolist()
data['idx_treatment'] = data['mh_treatment'].apply(lambda x: np.where(np.array(x) == 1)[0])#.tolist()
data['idx_diagnosis'] = data['mh_diagnosis'].apply(lambda x: np.where(np.array(x) == 1)[0])#.tolist()

print(data)

"""#Group by"""

data_gb = data.groupby('subject_id')

'''for name, group in data_gb:
  print(group['symptom'], name)'''
  
subjects= data['subject_id'].unique()

"""#single dim"""

class Symptom2Vec(nn.Module):
  def __init__(self, symptom_size, emb_dim=16):
    super(Symptom2Vec, self).__init__()


    self.rnn = nn.RNN(input_size=symptom_size, hidden_size=emb_dim, nonlinearity= 'tanh', bias=True, batch_first=True)
    #self.h0 = torch.unsqueeze(torch.unsqueeze(torch.randn(emb_dim), dim =0), dim = 0)

  def forward(self, symptom):

    o,h = self.rnn(symptom)
    #self.h0 = h

    return o,h

"""# Patient2Vec"""

class Patient2Vec(nn.Module):
  def __init__(self, symptom_size, treatment_size, emb_dim=16):
    super(Patient2Vec, self).__init__()
    #self.emb_symptom = nn.Embedding(num_embeddings=symptom_size, embedding_dim=emb_dim)
    #self.emb_treatment = nn.Embedding(num_embeddings=treatment_size, embedding_dim=emb_dim)
    #self.emb_diagnosis = nn.Embedding(num_embeddings=diagnosis_size, embedding_dim=emb_dim)

    #matobbori kore ekta weight matrix banaisi
    self.fc_sym = nn.Linear(in_features=symptom_size+emb_dim, out_features=emb_dim, bias=True)
    self.fc_trt = nn.Linear(in_features=treatment_size+emb_dim, out_features=emb_dim, bias=True)

    self.fc1 = nn.Linear(in_features=emb_dim, out_features=emb_dim,bias = False)
    self.rnn = nn.GRU(input_size=emb_dim, hidden_size=emb_dim, bias=True)
    self.o_hidden= torch.rand(emb_dim)

  def forward(self, symptom, treatment):
    cat_sym_out= torch.cat([symptom, torch.unsqueeze(self.o_hidden, dim=1)], dim=1)
    cat_trt_out= torch.cat([treatment, torch.unsqueeze(self.o_hidden, dim=1)], dim=1)

    a_sym = self.fc_sym(cat_sym_out)
    a_trt = self.fc_trt(cat_trt_out)

    a= a_sym * a_trt
    o_hidden,_ = self.rnn(F.tanh(self.fc1(a)))

    return o_hidden

"""#Diagnosis_Pred"""

class Diagnosis_Pred(nn.Module):
  def __init__(self, emb_dim, diagnosis_size):
    super(Diagnosis_Pred, self).__init__()

    self.fc1 = nn.Linear(in_features = emb_dim, out_features = diagnosis_size)

  def forward(self, o_hidden):
      return F.softmax(self.fc1(o_hidden))

sym2vec = Symptom2Vec(len(vocab_symptom)).to(device)
#pat2vec = Patient2Vec(len(vocab_symptom), len(vocab_treatment) )
diag_pred = Diagnosis_Pred(emb_dim= 16,diagnosis_size= len(vocab_diagnosis)).to(device)

params = list(sym2vec.parameters()) + list(diag_pred.parameters())

optimizer = torch.optim.Adam(params, lr=1e-3)
criterion= nn.BCELoss()

"""Dataset"""

class Mimic3(Dataset):
    # load the dataset
    def __init__(self,data_gb, subjects):
        self.subjects= subjects
        self.data_gb = data_gb

    # number of rows in the dataset
    def __len__(self):
        return self.subjects.shape[0]

    # get a row at an index
    def __getitem__(self, idx):
        subject_id=subjects[idx]
        group = self.data_gb.get_group(subject_id)
        #s1 = np.array(group['symptom'].values.tolist())
        #print(s1.shape)
        s = torch.from_numpy(np.array(group['mh_symptom'].values.tolist(), dtype = 'float32') )
        d = torch.from_numpy(np.array(group['mh_diagnosis'].values.tolist(),dtype = 'float32'))

        
        return [s, d]
165520

class Mimic(Dataset):
    # load the dataset
    def __init__(self, symptom, treatment, diagnosis):
        #print(symptom)
        #self.s= torch.from_numpy(symptom)
        #self.t = torch.from_numpy(treatment)
        #self.d = torch.from_numpy(diagnosis)

        self.s= torch.from_numpy(np.array(symptom.values.tolist()))
        self.t= torch.from_numpy(np.array(treatment.values.tolist()))
        self.d= torch.from_numpy(np.array(diagnosis.values.tolist()))

        print(type(self.s))
    # number of rows in the dataset
    def __len__(self):
        return self.s.shape[0]

    # get a row at an index
    def __getitem__(self, idx):
        return [self.s[idx], self.t[idx], self.d[idx]]

#train_set = Mimic(data['mh_symptom'].to_numpy(), data['mh_treatment'].to_numpy(),data['mh_diagnosis'].to_numpy())
#train_set = Mimic(data['mh_symptom'], data['mh_treatment'],data['mh_diagnosis'])
full_set = Mimic3(data_gb, subjects)
total_size = len(full_set)
val_size = int(0.1 * total_size)
test_size = val_size
train_size = total_size - val_size - test_size
train_set, val_set, test_set = torch.utils.data.random_split(full_set, [train_size, val_size, test_size])



def collate_fn(batch):
  #print(type(batch[0][0]))
  symptoms = []
  treatments = []
  for patient in batch:
    symptoms.append(patient[0])
    treatments.append(patient[1])

  symptoms = pad_sequence(symptoms, batch_first=True)
  treatments = pad_sequence(treatments, batch_first=True)
  return symptoms, treatments

train_loader= DataLoader(full_set, batch_size= 24, shuffle = True, collate_fn=collate_fn)
val_loader= DataLoader(val_set, batch_size= 24, shuffle = True, collate_fn=collate_fn)
test_loader= DataLoader(test_set, batch_size= 24, shuffle = False, collate_fn=collate_fn)

sym2vec_params = sum(p.numel() for p in sym2vec.parameters())
sym2vec_train_params = sum(p.numel() for p in sym2vec.parameters() if p.requires_grad)
diag_pred_params = sum(p.numel() for p in diag_pred.parameters())
diag_pred_train_params = sum(p.numel() for p in diag_pred.parameters() if p.requires_grad)
print(sym2vec_params, sym2vec_train_params)
print(diag_pred_params, diag_pred_train_params)

import matplotlib.pyplot as plt

def my_plot(epochs, loss):
    plt.plot(epochs, loss)
    plt.xlabel('Epoch No')
    plt.ylabel('BCE Loss')
    plt.show()

num_epochs = 250
loss_vals =  []
for epoch in range(num_epochs):
    # enumerate mini batches
    epoch_loss= []
    for i, (symptom, diagnosis) in enumerate(train_loader):
        # clear the gradients
        optimizer.zero_grad()
        # compute the model output
        #rep = pat2vec(symptom, treatment)
        rep,_ = sym2vec(symptom.to(device))
        yhat = diag_pred(rep)
        # calculate loss
        loss = criterion(yhat, diagnosis)
        # credit assignment
        loss.backward(retain_graph=True)
        epoch_loss.append(loss.item())
        # update model weights
        optimizer.step()
    loss_vals.append(sum(epoch_loss)/len(epoch_loss))
# plotting
my_plot(np.linspace(1, num_epochs, num_epochs).astype(int), loss_vals)
